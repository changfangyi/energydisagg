{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from time import strftime\n",
    "import numpy as np\n",
    "\n",
    "path = '/Users/kang/Desktop/energydisagg/data'# multi_group\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    prepare training data from 'multi_group', which can be downloaded from google drive\\n    collection : data_in_dictionary, training data\\n    train_builing : IdList, the building for training\\n    bprob = IdProbility, the probabilities for the training builings. \\n    activation_prob = ActivationProbility, the probabilities for the activations\\n    \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    prepare training data from 'multi_group', which can be downloaded from google drive\n",
    "    collection : data_in_dictionary, training data\n",
    "    train_builing : IdList, the building for training\n",
    "    bprob = IdProbility, the probabilities for the training builings. \n",
    "    activation_prob = ActivationProbility, the probabilities for the activations\n",
    "    \n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_builing = [14, 19, 28, 39]\n",
    "bprob = []\n",
    "collection = {} # training data\n",
    "activation_prob = {} #  ActivationProbility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the related config\n",
    "for item in sorted(train_builing):\n",
    "    pathfile = os.path.join(path,'multi_group',str(item))\n",
    "    aprob = []\n",
    "    ActivationsList = os.listdir(pathfile)\n",
    "    ActivationCollection = {}\n",
    "\n",
    "    for activation in ActivationsList:\n",
    "        activation_data = pd.read_csv(pathfile+'/'+activation, index_col=0)\n",
    "        #print(len(activation_data))\n",
    "        aprob.append(len(activation_data))\n",
    "        ActivationCollection[str(activation[:-15])]=activation_data\n",
    "    bprob.append(sum(aprob))\n",
    "    collection['id_'+str(item)] =  ActivationCollection\n",
    "    activation_prob['id_'+ str(item)] = [i/sum(aprob) for i in aprob]\n",
    "building_prob = [i/sum(bprob) for i in bprob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sequence(object):\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    input : np.ndarray\n",
    "    target : np.ndarray\n",
    "    all_appliances : pd.DataFrame\n",
    "        Column names are the appliance names.\n",
    "    metadata : dict\n",
    "    weights : np.ndarray or None\n",
    "    \"\"\"\n",
    "    def __init__(self, shape, target_channels_in_list):\n",
    "        self.input = np.zeros(shape, dtype=np.float32)\n",
    "        self.target = {}\n",
    "        for target_channel in target_channels_in_list:\n",
    "            self.target[str(target_channel)] = np.zeros(shape, dtype=np.float32)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the RealSource, which will replace the original one\n",
    "class RealSource(object):\n",
    "    \n",
    "    def __init__(self, data_in_dictionary, target_channels_in_list, seq_length, IdList, IdProbility, ActivationProbility,\n",
    "                num_seq_per_batch=32):\n",
    "        self.data_in_dictionary = data_in_dictionary\n",
    "        self.target_channels_in_list = target_channels_in_list\n",
    "        self.seq_length = seq_length\n",
    "        self.IdList = IdList\n",
    "        self.IdProbility = IdProbility\n",
    "        self.ActivationProbility = ActivationProbility\n",
    "        self.num_seq_per_batch = num_seq_per_batch\n",
    "    \n",
    "    def _select_building(self, IdList, IdProbility):\n",
    "        \"\"\"\n",
    "        For Example:\n",
    "        \n",
    "        _select_building(train_builing, building_prob), where\n",
    "        train_builing = [1, 14, 19]\n",
    "        building_prob = [0.5, 0.2, 0.3]\n",
    "        \"\"\"\n",
    "        return np.random.choice(IdList, 1, p=IdProbility)\n",
    "    \n",
    "    def _select_activation(self, ActivationList, ActivationProbility):\n",
    "        \"\"\"\n",
    "        For Example:\n",
    "        \n",
    "        _select_activation(range(len(activation_prob['id_1'])), activation_prob['id_1']), where\n",
    "        range(len(activation_prob['id_1'])) = [0,1,2,3,5]\n",
    "        activation_prob['id_1'] = [0.1, 0.1, 0.3, 0.2, 0.3]\n",
    "        \"\"\"\n",
    "        return np.random.choice(ActivationList, 1, p=ActivationProbility)\n",
    "    \n",
    "    def get_seq_and_check(self, data, IdList, IdProbility, ActivationProbility):\n",
    "        \"\"\"\n",
    "        get a batch of data\n",
    "        For Example:\n",
    "        get_seq_and_check(collection, train_builing, building_prob, activation_prob)\n",
    "        collection = data\n",
    "        train_builing = [1, 14, 19]\n",
    "        building_prob = [0.5, 0.2, 0.3]\n",
    "        activation_prob = {'id_1':[0.1, 0.1, 0.3, 0.2, 0.3], \n",
    "                            'id_14':[0.1, 0.1, 0.3, 0.2, 0.3],\n",
    "                            'id_19':[0.1, 0.1, 0.3, 0.2, 0.3]}\n",
    "        \n",
    "        Warning:\n",
    "        ------------------------------------------------------------------------\n",
    "            Currently, setting max_iter == 120, the gap within select_start and end is self.seq_length*2 points\n",
    "            If the gap is self.seq_length points, it will not success. The cause needs to be figured out\n",
    "            In the prototype stage, using main as target\n",
    "        \"\"\"\n",
    "        success_for_enough_data = False\n",
    "        max_iter_for_enough_data = 0\n",
    "        while not success_for_enough_data:\n",
    "            max_iter_for_enough_data +=1\n",
    "            select_building = self._select_building(IdList, IdProbility)[0]\n",
    "            select_building = 'id_'+str(select_building)\n",
    "            activation_prob_for_the_select_building = ActivationProbility[select_building ]\n",
    "            select_activation = self._select_activation(range(len(activation_prob_for_the_select_building)), \n",
    "                                           activation_prob_for_the_select_building)[0]      \n",
    "            get_seq_before_check = data[select_building][str(select_activation)]\n",
    "            # double check that the index is datetime format\n",
    "            get_seq_before_check.index = pd.to_datetime(get_seq_before_check.index)\n",
    "            if len(get_seq_before_check)>=self.seq_length or  max_iter_for_enough_data >= 32 :\n",
    "                 success_for_enough_data = True\n",
    "      \n",
    "        success = False\n",
    "        max_iter = 0\n",
    "        while not success:\n",
    "            max_iter +=1\n",
    "            select_start = get_seq_before_check.sample(n=1).index[0]\n",
    "            end = select_start + timedelta(seconds = 60*self.seq_length*2) \n",
    "            if len(get_seq_before_check[select_start:end])>=self.seq_length or max_iter==120:\n",
    "                success = True\n",
    "                get_seq_after_check = get_seq_before_check[select_start:end]\n",
    "        \n",
    "        if max_iter==120:\n",
    "            seq = None\n",
    "\n",
    "        else:\n",
    "            del get_seq_before_check\n",
    "            #seq = Sequence(self.seq_length)\n",
    "            seq = Sequence(self.seq_length, self.target_channels_in_list)\n",
    "            seq.input = np.array(get_seq_after_check[self.target_channels_in_list[0]].values[:self.seq_length])\n",
    "            #for target in self.target_channels_in_list[1:]:\n",
    "            #    seq.target = np.array(get_seq_after_check[target].values[:self.seq_length])\n",
    "            for target in self.target_channels_in_list[1:]:\n",
    "                seq.target[str(target)] = np.array(get_seq_after_check[target].values[:self.seq_length])\n",
    "        return seq\n",
    "    \n",
    "    def _get_sequence(self):\n",
    "        seq=self.get_seq_and_check(data = self.data_in_dictionary, \n",
    "                                   IdList = self.IdList, \n",
    "                                   IdProbility = self.IdProbility, \n",
    "                                   ActivationProbility = self.ActivationProbility)\n",
    "        return seq\n",
    "    \n",
    "    def get_batch(self):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        A Batch object or None if source iterator has hit a StopIteration.\n",
    "        \"\"\"\n",
    "\n",
    "        input_sequences = []\n",
    "        target_sequences = {}\n",
    "        none_happened = False\n",
    "        for target in self.target_channels_in_list[1:]:\n",
    "                target_sequences[str(target)] = []\n",
    "\n",
    "        for i in range(self.num_seq_per_batch):\n",
    "            seq = self._get_sequence()\n",
    "            \n",
    "            if seq is None:\n",
    "                none_happened = True\n",
    "            else:\n",
    "                input_sequences.append(seq.input.reshape(self.seq_length,1))\n",
    "                #target_sequences.append(seq.target.reshape(self.seq_length,1))\n",
    "                for target in self.target_channels_in_list[1:]:\n",
    "                    target_sequences[str(target)].append(seq.target[str(target)].reshape(self.seq_length,1))\n",
    "                \n",
    "        if not none_happened:\n",
    "            input_sequences = np.asarray(input_sequences).reshape(self.num_seq_per_batch,self.seq_length,1)\n",
    "            #target_sequences = np.asarray(target_sequences).reshape(self.num_seq_per_batch,self.seq_length,1)\n",
    "            for target in self.target_channels_in_list[1:]:\n",
    "                target_sequences[str(target)] = np.asarray(target_sequences[str(target)]).reshape(self.num_seq_per_batch,self.seq_length,1)\n",
    "        else:\n",
    "            input_sequences = None\n",
    "            target_sequences = None\n",
    "            \n",
    "        return input_sequences, target_sequences\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SynSource(RealSource):\n",
    "    def __init__(self, data_in_dictionary, target_channels_in_list, seq_length, IdList, IdProbility, ActivationProbility,\n",
    "                num_seq_per_batch=32):\n",
    "        \n",
    "        self.data_in_dictionary = data_in_dictionary\n",
    "        self.target_channels_in_list = target_channels_in_list\n",
    "        self.seq_length = seq_length\n",
    "        self.IdList = IdList\n",
    "        self.IdProbility = IdProbility\n",
    "        self.ActivationProbility = ActivationProbility\n",
    "        self.num_seq_per_batch = num_seq_per_batch\n",
    "        \n",
    "    def _get_sequence(self):\n",
    "        seq = Sequence(self.seq_length, self.target_channels_in_list)\n",
    "   \n",
    "        for target in self.target_channels_in_list[1:]:\n",
    "            channel_seq = super(SynSource,self)._get_sequence()\n",
    "            seq.target[str(target)] = np.array(channel_seq.target[str(target)])\n",
    "            seq.input += seq.target[str(target)]\n",
    "            \n",
    "        return seq\n",
    "    \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = SynSource(data_in_dictionary = collection, \n",
    "                  target_channels_in_list = ['main','fridge','air conditioner'], \n",
    "                  seq_length=60, \n",
    "                  IdList = train_builing, \n",
    "                  IdProbility = building_prob,\n",
    "                  ActivationProbility = activation_prob)\n",
    "main, target = syn.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  25.],\n",
       "       [  25.],\n",
       "       [1008.],\n",
       "       [1002.],\n",
       "       [1064.],\n",
       "       [1073.],\n",
       "       [1078.],\n",
       "       [ 208.],\n",
       "       [1212.],\n",
       "       [1212.],\n",
       "       [1085.],\n",
       "       [ 912.],\n",
       "       [ 908.],\n",
       "       [ 908.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [ 847.],\n",
       "       [ 883.],\n",
       "       [ 890.],\n",
       "       [ 890.],\n",
       "       [ 899.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [ 239.],\n",
       "       [1002.],\n",
       "       [1071.],\n",
       "       [1071.],\n",
       "       [1083.],\n",
       "       [1092.],\n",
       "       [1092.],\n",
       "       [1089.],\n",
       "       [1088.],\n",
       "       [ 918.],\n",
       "       [ 909.],\n",
       "       [ 909.],\n",
       "       [ 906.],\n",
       "       [ 902.],\n",
       "       [ 904.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [ 847.],\n",
       "       [ 889.],\n",
       "       [ 909.],\n",
       "       [ 909.],\n",
       "       [ 916.],\n",
       "       [1124.],\n",
       "       [ 210.],\n",
       "       [ 210.],\n",
       "       [1269.],\n",
       "       [1054.],\n",
       "       [1053.],\n",
       "       [1103.],\n",
       "       [1107.],\n",
       "       [ 920.],\n",
       "       [ 931.]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  25.],\n",
       "       [  25.],\n",
       "       [1008.],\n",
       "       [1002.],\n",
       "       [1064.],\n",
       "       [1073.],\n",
       "       [1078.],\n",
       "       [ 208.],\n",
       "       [1212.],\n",
       "       [1212.],\n",
       "       [1085.],\n",
       "       [ 912.],\n",
       "       [ 908.],\n",
       "       [ 908.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [ 847.],\n",
       "       [ 883.],\n",
       "       [ 890.],\n",
       "       [ 890.],\n",
       "       [ 899.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [ 239.],\n",
       "       [1002.],\n",
       "       [1071.],\n",
       "       [1071.],\n",
       "       [1083.],\n",
       "       [1092.],\n",
       "       [1092.],\n",
       "       [1089.],\n",
       "       [1088.],\n",
       "       [ 918.],\n",
       "       [ 909.],\n",
       "       [ 909.],\n",
       "       [ 906.],\n",
       "       [ 902.],\n",
       "       [ 904.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [  25.],\n",
       "       [ 847.],\n",
       "       [ 889.],\n",
       "       [ 909.],\n",
       "       [ 909.],\n",
       "       [ 916.],\n",
       "       [1124.],\n",
       "       [ 210.],\n",
       "       [ 210.],\n",
       "       [1269.],\n",
       "       [1054.],\n",
       "       [1053.],\n",
       "       [1103.],\n",
       "       [1107.],\n",
       "       [ 920.],\n",
       "       [ 931.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target['air conditioner'][31]+target['fridge'][31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
