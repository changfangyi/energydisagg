{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from time import strftime\n",
    "import numpy as np\n",
    "\n",
    "path = '/home/nilm/Desktop/energydisagg/data' # multi_group\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    prepare training data from 'multi_group', which can be downloaded from google drive\\n    collection : data_in_dictionary, training data\\n    train_builing : IdList, the building for training\\n    bprob = IdProbility, the probabilities for the training builings. \\n    activation_prob = ActivationProbility, the probabilities for the activations\\n    \\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    prepare training data from 'multi_group', which can be downloaded from google drive\n",
    "    collection : data_in_dictionary, training data\n",
    "    train_builing : IdList, the building for training\n",
    "    bprob = IdProbility, the probabilities for the training builings. \n",
    "    activation_prob = ActivationProbility, the probabilities for the activations\n",
    "    \n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_builing = [1, 14, 19, 28, 39, 41, 51]\n",
    "channels = ['main','fridge','bottle warmer']\n",
    "bprob = []\n",
    "collection = {} # training data\n",
    "activation_prob = {} #  ActivationProbility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the related config\n",
    "for item in sorted(train_builing):\n",
    "    pathfile = os.path.join(path,'multi_group',str(item))\n",
    "    aprob = []\n",
    "    ActivationsList = os.listdir(pathfile)\n",
    "    ActivationCollection = {}\n",
    "\n",
    "    for activation in ActivationsList:\n",
    "        activation_data = pd.read_csv(pathfile+'/'+activation, index_col=0)\n",
    "        #print(len(activation_data))\n",
    "        aprob.append(len(activation_data))\n",
    "        ActivationCollection[str(activation[:-15])]=activation_data\n",
    "    bprob.append(sum(aprob))\n",
    "    collection['id_'+str(item)] =  ActivationCollection\n",
    "    activation_prob['id_'+ str(item)] = [i/sum(aprob) for i in aprob]\n",
    "building_prob = [i/sum(bprob) for i in bprob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequence(object):\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    input : np.ndarray\n",
    "    target : np.ndarray\n",
    "    all_appliances : pd.DataFrame\n",
    "        Column names are the appliance names.\n",
    "    metadata : dict\n",
    "    weights : np.ndarray or None\n",
    "    \"\"\"\n",
    "    def __init__(self, shape, target_channels_in_list):\n",
    "        self.input = np.zeros(shape, dtype=np.float32)\n",
    "        self.target = {}\n",
    "        for target_channel in target_channels_in_list:\n",
    "            self.target[str(target_channel)] = np.zeros(shape, dtype=np.float32)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the RealSource, which will replace the original one\n",
    "class RealSource(object):\n",
    "    \n",
    "    def __init__(self, data_in_dictionary, target_channels_in_list, seq_length, IdList, IdProbility, ActivationProbility,\n",
    "                num_seq_per_batch=32):\n",
    "        self.data_in_dictionary = data_in_dictionary\n",
    "        self.target_channels_in_list = target_channels_in_list\n",
    "        self.seq_length = seq_length\n",
    "        self.IdList = IdList\n",
    "        self.IdProbility = IdProbility\n",
    "        self.ActivationProbility = ActivationProbility\n",
    "        self.num_seq_per_batch = num_seq_per_batch\n",
    "    \n",
    "    def _select_building(self, IdList, IdProbility):\n",
    "        \"\"\"\n",
    "        For Example:\n",
    "        \n",
    "        _select_building(train_builing, building_prob), where\n",
    "        train_builing = [1, 14, 19]\n",
    "        building_prob = [0.5, 0.2, 0.3]\n",
    "        \"\"\"\n",
    "        return np.random.choice(IdList, 1, p=IdProbility)\n",
    "    \n",
    "    def _select_activation(self, ActivationList, ActivationProbility):\n",
    "        \"\"\"\n",
    "        For Example:\n",
    "        \n",
    "        _select_activation(range(len(activation_prob['id_1'])), activation_prob['id_1']), where\n",
    "        range(len(activation_prob['id_1'])) = [0,1,2,3,5]\n",
    "        activation_prob['id_1'] = [0.1, 0.1, 0.3, 0.2, 0.3]\n",
    "        \"\"\"\n",
    "        return np.random.choice(ActivationList, 1, p=ActivationProbility)\n",
    "    \n",
    "    def get_seq_and_check(self, data, IdList, IdProbility, ActivationProbility):\n",
    "        \"\"\"\n",
    "        get a batch of data\n",
    "        For Example:\n",
    "        get_seq_and_check(collection, train_builing, building_prob, activation_prob)\n",
    "        collection = data\n",
    "        train_builing = [1, 14, 19]\n",
    "        building_prob = [0.5, 0.2, 0.3]\n",
    "        activation_prob = {'id_1':[0.1, 0.1, 0.3, 0.2, 0.3], \n",
    "                            'id_14':[0.1, 0.1, 0.3, 0.2, 0.3],\n",
    "                            'id_19':[0.1, 0.1, 0.3, 0.2, 0.3]}\n",
    "        \n",
    "        Warning:\n",
    "        ------------------------------------------------------------------------\n",
    "            Currently, setting max_iter == 120, the gap within select_start and end is self.seq_length*2 points\n",
    "            If the gap is self.seq_length points, it will not success. The cause needs to be figured out\n",
    "            In the prototype stage, using main as target\n",
    "        \"\"\"\n",
    "        success_for_enough_data = False\n",
    "        max_iter_for_enough_data = 0\n",
    "        while not success_for_enough_data:\n",
    "            max_iter_for_enough_data +=1\n",
    "            select_building = self._select_building(IdList, IdProbility)[0]\n",
    "            select_building = 'id_'+str(select_building)\n",
    "            activation_prob_for_the_select_building = ActivationProbility[select_building ]\n",
    "            select_activation = self._select_activation(range(len(activation_prob_for_the_select_building)), \n",
    "                                           activation_prob_for_the_select_building)[0]      \n",
    "            get_seq_before_check = data[select_building][str(select_activation)]\n",
    "            # double check that the index is datetime format\n",
    "            get_seq_before_check.index = pd.to_datetime(get_seq_before_check.index)\n",
    "            if len(get_seq_before_check)>=self.seq_length or  max_iter_for_enough_data >= 32 :\n",
    "                 success_for_enough_data = True\n",
    "      \n",
    "        success = False\n",
    "        max_iter = 0\n",
    "        while not success:\n",
    "            max_iter +=1\n",
    "            select_start = get_seq_before_check.sample(n=1).index[0]\n",
    "            end = select_start + timedelta(seconds = 60*self.seq_length*2) \n",
    "            if len(get_seq_before_check[select_start:end])>=self.seq_length or max_iter==120:\n",
    "                success = True\n",
    "                get_seq_after_check = get_seq_before_check[select_start:end]\n",
    "        \n",
    "        if max_iter==120:\n",
    "            seq = None\n",
    "\n",
    "        else:\n",
    "            del get_seq_before_check\n",
    "            #seq = Sequence(self.seq_length)\n",
    "            seq = Sequence(self.seq_length, self.target_channels_in_list)\n",
    "            seq.input = np.array(get_seq_after_check[self.target_channels_in_list[0]].values[:self.seq_length])\n",
    "            #for target in self.target_channels_in_list[1:]:\n",
    "            #    seq.target = np.array(get_seq_after_check[target].values[:self.seq_length])\n",
    "            for target in self.target_channels_in_list[1:]:\n",
    "                seq.target[str(target)] = np.array(get_seq_after_check[target].values[:self.seq_length])\n",
    "        return seq\n",
    "    \n",
    "    def _get_sequence(self):\n",
    "        seq=self.get_seq_and_check(data = self.data_in_dictionary, \n",
    "                                   IdList = self.IdList, \n",
    "                                   IdProbility = self.IdProbility, \n",
    "                                   ActivationProbility = self.ActivationProbility)\n",
    "        return seq\n",
    "    \n",
    "    def get_batch(self):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        A Batch object or None if source iterator has hit a StopIteration.\n",
    "        \"\"\"\n",
    "\n",
    "        input_sequences = []\n",
    "        target_sequences = {}\n",
    "        none_happened = False\n",
    "        for target in self.target_channels_in_list[1:]:\n",
    "                target_sequences[str(target)] = []\n",
    "\n",
    "        for i in range(self.num_seq_per_batch):\n",
    "            seq = self._get_sequence()\n",
    "            \n",
    "            if seq is None:\n",
    "                none_happened = True\n",
    "            else:\n",
    "                input_sequences.append(seq.input.reshape(self.seq_length,1))\n",
    "                #target_sequences.append(seq.target.reshape(self.seq_length,1))\n",
    "                for target in self.target_channels_in_list[1:]:\n",
    "                    target_sequences[str(target)].append(seq.target[str(target)].reshape(self.seq_length,1))\n",
    "                \n",
    "        if not none_happened:\n",
    "            input_sequences = np.asarray(input_sequences).reshape(self.num_seq_per_batch,self.seq_length,1)\n",
    "            #target_sequences = np.asarray(target_sequences).reshape(self.num_seq_per_batch,self.seq_length,1)\n",
    "            for target in self.target_channels_in_list[1:]:\n",
    "                target_sequences[str(target)] = np.asarray(target_sequences[str(target)]).reshape(self.num_seq_per_batch,self.seq_length,1)\n",
    "        else:\n",
    "            input_sequences = None\n",
    "            target_sequences = None\n",
    "            \n",
    "        return input_sequences, target_sequences\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynSource(RealSource):\n",
    "    def __init__(self, data_in_dictionary, target_channels_in_list, seq_length, IdList, IdProbility, ActivationProbility,\n",
    "                num_seq_per_batch=32):\n",
    "        \n",
    "        self.data_in_dictionary = data_in_dictionary\n",
    "        self.target_channels_in_list = target_channels_in_list\n",
    "        self.seq_length = seq_length\n",
    "        self.IdList = IdList\n",
    "        self.IdProbility = IdProbility\n",
    "        self.ActivationProbility = ActivationProbility\n",
    "        self.num_seq_per_batch = num_seq_per_batch\n",
    "        \n",
    "    def _get_sequence(self):\n",
    "        seq = Sequence(self.seq_length, self.target_channels_in_list)\n",
    "   \n",
    "        for target in self.target_channels_in_list[1:]:\n",
    "            channel_seq = super(SynSource,self)._get_sequence()\n",
    "            if channel_seq is None:\n",
    "                seq.target[str(target)] = np.array(np.zeros(self.seq_length))\n",
    "            else:\n",
    "                seq.target[str(target)] = np.array(channel_seq.target[str(target)])\n",
    "            seq.input += seq.target[str(target)]\n",
    "            \n",
    "        return seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation, Reshape, Flatten, Conv1D, MaxPooling1D, Dropout, LSTM, TimeDistributed, Bidirectional\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "MODEL_CONV_FILTERS = 32\n",
    "MODEL_CONV_KERNEL_SIZE = 18\n",
    "MODEL_CONV_STRIDES = 1\n",
    "MODEL_CONV_PADDING = 'same'\n",
    "\n",
    "\n",
    "\n",
    "seq_length = 60\n",
    "\n",
    "# conv\n",
    "x = Input(shape=(60,1))\n",
    "conv_1 = Conv1D(filters=MODEL_CONV_FILTERS, kernel_size=MODEL_CONV_KERNEL_SIZE, padding=MODEL_CONV_PADDING, activation='relu')(x)\n",
    "drop_1 = Dropout(0.12)(conv_1)\n",
    "\n",
    "conv_2 = Conv1D(filters=64, kernel_size=12, padding=MODEL_CONV_PADDING, activation='relu')(drop_1)\n",
    "drop_2 = Dropout(0.14)(conv_2)\n",
    "\n",
    "conv_3 = Conv1D(filters=128, kernel_size=7, padding=MODEL_CONV_PADDING, activation='relu')(drop_2)\n",
    "pool_3 = MaxPooling1D(pool_size=2)(conv_3)\n",
    "drop_3 = Dropout(0.18)(pool_3)\n",
    "\n",
    "conv_4 = Conv1D(filters=128, kernel_size=3, padding=MODEL_CONV_PADDING, activation='relu')(drop_3)\n",
    "pool_4 = MaxPooling1D(pool_size=2)(conv_4)\n",
    "drop_4 = Dropout(0.2)(pool_4)\n",
    "\n",
    "# reshape\n",
    "flat_4 = Flatten()(drop_4)\n",
    "\n",
    "dense_5 = Dense(1280, activation='relu')(flat_4)\n",
    "drop_5 = Dropout(0.16)(dense_5)\n",
    "\n",
    "dense_6 = Dense(960, activation='relu')(drop_5)\n",
    "drop_6 = Dropout(0.14)(dense_6)\n",
    "\n",
    "dense_7 = Dense(720, activation='relu')(drop_6)\n",
    "drop_7 = Dropout(0.12)(dense_7)\n",
    "\n",
    "reshape_8 = Reshape(target_shape=(seq_length, 12))(drop_7)\n",
    "\n",
    "outputs_disaggregation = []\n",
    "\n",
    "for appliance_name in channels[1:]:\n",
    "    biLSTM_1 = Bidirectional(LSTM(6, return_sequences=True))(reshape_8)\n",
    "    biLSTM_2 = Bidirectional(LSTM(3, return_sequences=True))(biLSTM_1)\n",
    "    outputs_disaggregation.append(TimeDistributed(Dense(1, activation='relu'), name=appliance_name.replace(\" \", \"_\"))(biLSTM_2))\n",
    "\n",
    "model = Model(inputs=x, outputs=outputs_disaggregation)\n",
    "optimizer = RMSprop(lr=0.001, clipnorm=4)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = RealSource(data_in_dictionary = collection, \n",
    "                  target_channels_in_list = channels, \n",
    "                  seq_length=60, \n",
    "                  IdList = train_builing, \n",
    "                  IdProbility = building_prob,\n",
    "                  ActivationProbility = activation_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = SynSource(data_in_dictionary = collection, \n",
    "                  target_channels_in_list = channels, \n",
    "                  seq_length=60, \n",
    "                  IdList = train_builing, \n",
    "                  IdProbility = building_prob,\n",
    "                  ActivationProbility = activation_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0 , Time : 2018-06-22_12_24\n",
      "\n",
      "loss=15623.1982, fridge_loss=4261.1982, bottle_warmer_loss=11362.0000, fridge_mean_absolute_error=38.9817, fridge_mean_squared_error=4261.1978, bottle_warmer_mean_absolute_error=44.2301, bottle_warmer_mean_squared_error=11361.9990, Step : 100 , Time : 2018-06-22_12_25\n",
      "\n",
      "loss=6552.0029, fridge_loss=3700.3181, bottle_warmer_loss=2851.6846, fridge_mean_absolute_error=38.9985, fridge_mean_squared_error=3700.3174, bottle_warmer_mean_absolute_error=27.4462, bottle_warmer_mean_squared_error=2851.6841, Step : 200 , Time : 2018-06-22_12_26\n",
      "\n",
      "loss=8270.9062, fridge_loss=1964.4570, bottle_warmer_loss=6306.4487, fridge_mean_absolute_error=34.3267, fridge_mean_squared_error=1964.4568, bottle_warmer_mean_absolute_error=21.3720, bottle_warmer_mean_squared_error=6306.4443, Step : 300 , Time : 2018-06-22_12_26\n",
      "\n",
      "loss=8072.0142, fridge_loss=5476.7817, bottle_warmer_loss=2595.2324, fridge_mean_absolute_error=45.1808, fridge_mean_squared_error=5476.7783, bottle_warmer_mean_absolute_error=25.9210, bottle_warmer_mean_squared_error=2595.2329, "
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    if i%2==0:\n",
    "        main, target = real.get_batch()\n",
    "        while main is None or target is None:\n",
    "            main, target = real.get_batch()\n",
    "    else:\n",
    "        main, target = syn.get_batch()\n",
    "        while main is None or target is None:\n",
    "            main, target = syn.get_batch()\n",
    "        \n",
    "    train_metrics = model.train_on_batch(x=main, y=[target[channels[1]], target[channels[2]]])\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print('Step : {} , Time : {}\\n'.format(i,strftime('%Y-%m-%d_%H_%M')))\n",
    "        for i, metrics_name in enumerate(model.metrics_names):\n",
    "            print('{}={:.4f}, '.format(metrics_name, train_metrics[i]), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('multi_group_frige_bw_0622.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
